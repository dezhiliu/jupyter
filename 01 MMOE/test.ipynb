{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6849b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multi-gate Mixture-of-Experts demo with census income data.\n",
    "Copyright (c) 2018 Drawbridge, Inc\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Alvin Deng\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from mmoe import MMoE\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# Fix numpy seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "# Fix TensorFlow graph-level seed for reproducibility\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Simple callback to print out ROC-AUC\n",
    "class ROCCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data, test_data):\n",
    "        self.train_X = training_data[0]\n",
    "        self.train_Y = training_data[1]\n",
    "        self.validation_X = validation_data[0]\n",
    "        self.validation_Y = validation_data[1]\n",
    "        self.test_X = test_data[0]\n",
    "        self.test_Y = test_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        train_prediction = self.model.predict(self.train_X)\n",
    "        validation_prediction = self.model.predict(self.validation_X)\n",
    "        test_prediction = self.model.predict(self.test_X)\n",
    "\n",
    "        # Iterate through each task and output their ROC-AUC across different datasets\n",
    "        for index, output_name in enumerate(self.model.output_names):\n",
    "            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n",
    "            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n",
    "            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n",
    "            print(\n",
    "                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n",
    "                    output_name, round(train_roc_auc, 4),\n",
    "                    output_name, round(validation_roc_auc, 4),\n",
    "                    output_name, round(test_roc_auc, 4)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "\n",
    "def data_preparation():\n",
    "    # The column names are from\n",
    "    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n",
    "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
    "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
    "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
    "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
    "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
    "\n",
    "    # Load the dataset in Pandas\n",
    "    train_df = pd.read_csv(\n",
    "        'data/census-income.data.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    other_df = pd.read_csv(\n",
    "        'data/census-income.test.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "\n",
    "    # First group of tasks according to the paper\n",
    "    label_columns = ['income_50k', 'marital_stat']\n",
    "\n",
    "    # One-hot encoding categorical columns\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    train_raw_labels = train_df[label_columns]\n",
    "    other_raw_labels = other_df[label_columns]\n",
    "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "\n",
    "    # Filling the missing column in the other set\n",
    "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
    "\n",
    "    # One-hot encoding categorical labels\n",
    "    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "\n",
    "    dict_outputs = {\n",
    "        'income': train_income.shape[1],\n",
    "        'marital': train_marital.shape[1]\n",
    "    }\n",
    "    dict_train_labels = {\n",
    "        'income': train_income,\n",
    "        'marital': train_marital\n",
    "    }\n",
    "    dict_other_labels = {\n",
    "        'income': other_income,\n",
    "        'marital': other_marital\n",
    "    }\n",
    "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
    "\n",
    "    # Split the other dataset into 1:1 validation to test according to the paper\n",
    "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n",
    "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
    "    validation_data = transformed_other.iloc[validation_indices]\n",
    "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    test_data = transformed_other.iloc[test_indices]\n",
    "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    train_data = transformed_train\n",
    "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load the data\n",
    "    train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n",
    "    \n",
    "    #print(output_info)\n",
    "    \n",
    "    num_features = train_data.shape[1]\n",
    "\n",
    "#     print('Training data shape = {}'.format(train_data.shape))\n",
    "#     print('Validation data shape = {}'.format(validation_data.shape))\n",
    "#     print('Test data shape = {}'.format(test_data.shape))\n",
    "\n",
    "    # Set up the input layer\n",
    "    input_layer = Input(shape=(num_features,))\n",
    "\n",
    "    # Set up MMoE layer\n",
    "    mmoe_layers = MMoE(\n",
    "        units=4,\n",
    "        num_experts=8,\n",
    "        num_tasks=2\n",
    "    )(input_layer)\n",
    "\n",
    "    output_layers = []\n",
    "\n",
    "    # Build tower layer from MMoE layer\n",
    "    for index, task_layer in enumerate(mmoe_layers):\n",
    "        tower_layer = Dense(\n",
    "            units=8,\n",
    "            activation='relu',\n",
    "            kernel_initializer=VarianceScaling())(task_layer)\n",
    "        output_layer = Dense(\n",
    "            units=output_info[index][0],\n",
    "            name=output_info[index][1],\n",
    "            activation='softmax',\n",
    "            kernel_initializer=VarianceScaling())(tower_layer)\n",
    "        output_layers.append(output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=[input_layer], outputs=output_layers)\n",
    "    adam_optimizer = Adam()\n",
    "    model.compile(\n",
    "        loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n",
    "        optimizer=adam_optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Print out model architecture summary\n",
    "#     model.summary()\n",
    "    \n",
    "    print(type(train_data))\n",
    "\n",
    "    # Train the model\n",
    "#     model.fit(\n",
    "#         x=train_data,\n",
    "#         y=train_label,\n",
    "#         validation_data=(validation_data, validation_label),\n",
    "#         callbacks=[\n",
    "#             ROCCallback(\n",
    "#                 training_data=(train_data, train_label),\n",
    "#                 validation_data=(validation_data, validation_label),\n",
    "#                 test_data=(test_data, test_label)\n",
    "#             )\n",
    "#         ],\n",
    "#         epochs=2\n",
    "#     )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633229e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
